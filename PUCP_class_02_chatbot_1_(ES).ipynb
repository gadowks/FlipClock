{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PUCP-class-02 - chatbot-1 (ES).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gadowks/FlipClock/blob/master/PUCP_class_02_chatbot_1_(ES).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo99HKYqC7kx",
        "colab_type": "text"
      },
      "source": [
        "# **Clase 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw1TSzEH-XQj",
        "colab_type": "text"
      },
      "source": [
        "# Descarga del modelo word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75dfclUYu5r-",
        "colab_type": "code",
        "outputId": "8d5eda11-035f-4b34-9894-a616213745e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download es_core_news_sm #en_core_web_md\n",
        "#!python -m spacy download en_core_web_lg\n",
        "\n",
        "#Reiniciar el entorno de ejecución luego de descargar el modelo para que luego\n",
        "#pueda ser cargado sin errores"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting es_core_news_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz#egg=es_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-2.1.0/es_core_news_sm-2.1.0.tar.gz (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 733kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: es-core-news-sm\n",
            "  Building wheel for es-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for es-core-news-sm: filename=es_core_news_sm-2.1.0-cp36-none-any.whl size=11111557 sha256=d63cbb3c524056340302980600b952af419694c5454f8c319ff6f61fac90a592\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-y7vtxv8l/wheels/cc/ee/c4/68922955901918a9aaa82e828d4f7ee1ccfc861285277e79b7\n",
            "Successfully built es-core-news-sm\n",
            "Installing collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHOAb9JL-Tvl",
        "colab_type": "text"
      },
      "source": [
        "# Descarga y carga de los stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wghWTgu8uqlx",
        "colab_type": "code",
        "outputId": "c8984e6b-4960-4736-8065-cb584fafd5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords = stopwords.words('spanish')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzYYjIitHVds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx5Ck6Ge-Z2B",
        "colab_type": "text"
      },
      "source": [
        "# Limpieza de los stopwords en un texto"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQqsxMND-oPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(text):\n",
        "  text_filtered = \"\"\n",
        "  for word in text.split():\n",
        "    if word not in stopwords:\n",
        "      text_filtered += word + \" \"\n",
        "  return text_filtered"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPKUs2MJyudY",
        "colab_type": "code",
        "outputId": "4793d527-0953-4e99-c199-21401d30a8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text = \"\"\"When Sebastian Thrun started working on self-driving cars at \n",
        "        Google in 2007, few people outside of the company took him \n",
        "        seriously. “I can tell you very senior CEOs of major American \n",
        "        car companies would shake my hand and turn away because I wasn’t \n",
        "        worth talking to, said Thrun, in an interview with Recode earlier \n",
        "        this week.\"\"\"\n",
        "\n",
        "text = remove_stopwords(text)\n",
        "text\n",
        "#Quitamos las palabras que no generan valor, antes definidas en el stopword"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When Sebastian Thrun started working self-driving cars Google 2007, people outside company took seriously. “I tell senior CEOs major American car companies would shake hand turn away I wasn’t worth talking to, said Thrun, interview Recode earlier week. '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHx0ePxz-vBN",
        "colab_type": "text"
      },
      "source": [
        "# Cargar el modelo de word2vec y transformar un texto a un vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI9J3KY_vszn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "#nlp = spacy.load('en_core_web_sm')\n",
        "nlp = spacy.load('es_core_news_sm') # #en_core_web_md\n",
        "#nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgRSxZHA9_jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#El modelo word2vec obtendrá los vectores de cada palabra en el texto y hará una suma ponderada de todos ellos para devolver 1 solo vector\n",
        "vector = nlp(text).vector\n",
        "\n",
        "#Mostramos solo los primeros 10 valores\n",
        "# Ejemplo de vector de 2 dimensiones\n",
        "#  distancia entre dos palabras sinonimas\n",
        "#  [hi, hello]\n",
        "vector[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8A2FZiIJ26P",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw2ZqB7e_b9W",
        "colab_type": "text"
      },
      "source": [
        "# Creamos un pequeño dataset de intents asociados a sentencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P81rKRxQ0s0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Una palabra que representa una intencion, la relacionamos\n",
        "#*si\n",
        "# ya\n",
        "# vao\n",
        "# dale\n",
        "\n",
        "dataset = \"\"\"\n",
        "*Hola\n",
        "Holas\n",
        "Que hay\n",
        "Habla\n",
        "Que fue\n",
        "Dime\n",
        "\n",
        "*Comida\n",
        "Quieres ir a comer\n",
        "Vao a almorzar\n",
        "Hamma\n",
        "Richi\n",
        "\n",
        "*Sip\n",
        "ya\n",
        "See\n",
        "Claro\n",
        "Vao\n",
        "\n",
        "*Chau\n",
        "Alamos\n",
        "Nos vemos\n",
        "Bella ciao\n",
        "Bye bye\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3xXsBGMCoKA",
        "colab_type": "text"
      },
      "source": [
        "# Entrenamos un modelo con nuestro dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i69VBtvNNXG2",
        "colab_type": "text"
      },
      "source": [
        "## Métodos para crear el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDdnbArcC0DB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_intents_and_their_examples(dataset, intent_character = \"*\"):\n",
        "  filter_list = list(filter(None, dataset.split(\"\\n\")))\n",
        "\n",
        "  intents_examples = {}\n",
        "  intent = \"\"\n",
        "  for element in filter_list:\n",
        "    if element[0] == intent_character:\n",
        "      intent = element[1:]\n",
        "    else:\n",
        "      if intent not in intents_examples:\n",
        "        intents_examples[intent] = [element]\n",
        "      else:\n",
        "        intents_examples[intent].append(element)\n",
        "  return intents_examples\n",
        "\n",
        "def transform_examples_in_vectors(intents_examples, nlp):\n",
        "  intents_vector_examples = {}\n",
        "  for key, values in intents_examples.items():\n",
        "    vector_examples = []\n",
        "    for example in values:\n",
        "      vector_examples.append(nlp(example).vector)\n",
        "    \n",
        "    intents_vector_examples[key] = vector_examples\n",
        "  return intents_vector_examples\n",
        "\n",
        "def create_x_and_y(intents_vector_examples):\n",
        "  x = []\n",
        "  y = []\n",
        "  for label, vector_examples in intents_vector_examples.items():\n",
        "    x.extend(vector_examples)\n",
        "    y.extend([label] * len(vector_examples))\n",
        "  \n",
        "  return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-MS95lpNSJi",
        "colab_type": "text"
      },
      "source": [
        "## Creando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQQJ1tYqNN3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Obteniendo un diccionario de intents con sus sentencias\n",
        "intents_examples = filter_intents_and_their_examples(dataset)\n",
        "\n",
        "#Transformando las sentencias a vectores en el diccionario\n",
        "intents_vector_examples = transform_examples_in_vectors(intents_examples, nlp)\n",
        "\n",
        "#Obteniendo los nombres de los intents\n",
        "intents = list(intents_vector_examples.keys())\n",
        "\n",
        "#Obteniendo x,y para entrenar un modelo de Machine Learning\n",
        "x, y = create_x_and_y(intents_vector_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTwlDmNONESc",
        "colab_type": "code",
        "outputId": "3b1bc39e-b11c-4870-f58e-76221868c666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "intents_examples['Hola']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Holas', 'Que hay', 'Habla', 'Que fue', 'Dime']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcq3ANGMOX1z",
        "colab_type": "code",
        "outputId": "9e0cf3df-a43f-43ec-fc1d-aa388c2d239e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "intents"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hola', 'Comida', 'Sip', 'Chau']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIzThdL2NcqH",
        "colab_type": "text"
      },
      "source": [
        "## Entrenando el modelo de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN_aeCvINcKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1e165c45-a0f9-4a61-d86f-466569977f8b"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "decision_tree_classifier = DecisionTreeClassifier()\n",
        "decision_tree_classifier.fit(x, y)\n",
        "\n",
        "#Evaluacion del accuracy\n",
        "accuracy = decision_tree_classifier.score(x, y)\n",
        "accuracy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4ctaOWlQI-N",
        "colab_type": "text"
      },
      "source": [
        "## Visualización del árbol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-VGu0LEQmcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "fc72aaf8-9704-4909-a797-53ce54a07c0a"
      },
      "source": [
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "dot_data = tree.export_graphviz(decision_tree_classifier,\n",
        "                                out_file=None,\n",
        "                                class_names=intents,\n",
        "                                filled=True,\n",
        "                                rounded=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f9d30d78ef0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"436pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 436.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-429 432,-429 432,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f0f7fd\" stroke=\"#000000\" d=\"M193,-425C193,-425 86,-425 86,-425 80,-425 74,-419 74,-413 74,-413 74,-354 74,-354 74,-348 80,-342 86,-342 86,-342 193,-342 193,-342 199,-342 205,-348 205,-354 205,-354 205,-413 205,-413 205,-419 199,-425 193,-425\"/>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[20] &lt;= &#45;3.76</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.747</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 4, 5, 4]</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Sip</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#47e539\" stroke=\"#000000\" d=\"M119,-298.5C119,-298.5 12,-298.5 12,-298.5 6,-298.5 0,-292.5 0,-286.5 0,-286.5 0,-242.5 0,-242.5 0,-236.5 6,-230.5 12,-230.5 12,-230.5 119,-230.5 119,-230.5 125,-230.5 131,-236.5 131,-242.5 131,-242.5 131,-286.5 131,-286.5 131,-292.5 125,-298.5 119,-298.5\"/>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-283.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-268.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-253.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 4, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"65.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Comida</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M113.6184,-341.8796C106.7121,-330.7735 99.2361,-318.7513 92.2825,-307.5691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"95.0917,-305.4587 86.8387,-298.8149 89.1473,-309.1552 95.0917,-305.4587\"/>\n<text text-anchor=\"middle\" x=\"81.1619\" y=\"-319.4619\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e9f4fc\" stroke=\"#000000\" d=\"M268,-306C268,-306 161,-306 161,-306 155,-306 149,-300 149,-294 149,-294 149,-235 149,-235 149,-229 155,-223 161,-223 161,-223 268,-223 268,-223 274,-223 280,-229 280,-235 280,-235 280,-294 280,-294 280,-300 274,-306 268,-306\"/>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[44] &lt;= &#45;0.787</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.663</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0, 5, 4]</text>\n<text text-anchor=\"middle\" x=\"214.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Sip</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M165.7314,-341.8796C171.2373,-333.1434 177.1006,-323.8404 182.7824,-314.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"185.7857,-316.6242 188.1567,-306.2981 179.8637,-312.8919 185.7857,-316.6242\"/>\n<text text-anchor=\"middle\" x=\"193.6863\" y=\"-326.9789\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M193,-179.5C193,-179.5 86,-179.5 86,-179.5 80,-179.5 74,-173.5 74,-167.5 74,-167.5 74,-123.5 74,-123.5 74,-117.5 80,-111.5 86,-111.5 86,-111.5 193,-111.5 193,-111.5 199,-111.5 205,-117.5 205,-123.5 205,-123.5 205,-167.5 205,-167.5 205,-173.5 199,-179.5 193,-179.5\"/>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-164.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-149.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [4, 0, 0, 0]</text>\n<text text-anchor=\"middle\" x=\"139.5\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Hola</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M188.2686,-222.8796C181.269,-211.7735 173.692,-199.7513 166.6444,-188.5691\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"169.42,-186.4087 161.1271,-179.8149 163.498,-190.1411 169.42,-186.4087\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#d7ebfa\" stroke=\"#000000\" d=\"M342,-187C342,-187 235,-187 235,-187 229,-187 223,-181 223,-175 223,-175 223,-116 223,-116 223,-110 229,-104 235,-104 235,-104 342,-104 342,-104 348,-104 354,-110 354,-116 354,-116 354,-175 354,-175 354,-181 348,-187 342,-187\"/>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">X[33] &lt;= &#45;0.468</text>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.494</text>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 9</text>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 5, 4]</text>\n<text text-anchor=\"middle\" x=\"288.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Sip</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240.3816,-222.8796C245.8142,-214.1434 251.5992,-204.8404 257.2053,-195.8253\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"260.1993,-197.6383 262.5079,-187.2981 254.2549,-193.9418 260.1993,-197.6383\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#d739e5\" stroke=\"#000000\" d=\"M267,-68C267,-68 160,-68 160,-68 154,-68 148,-62 148,-56 148,-56 148,-12 148,-12 148,-6 154,0 160,0 160,0 267,0 267,0 273,0 279,-6 279,-12 279,-12 279,-56 279,-56 279,-62 273,-68 267,-68\"/>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4</text>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 0, 4]</text>\n<text text-anchor=\"middle\" x=\"213.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Chau</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M260.5728,-103.9815C254.5762,-95.0666 248.2296,-85.6313 242.2041,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"245.0328,-74.6078 236.5473,-68.2637 239.2245,-78.5147 245.0328,-74.6078\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M416,-68C416,-68 309,-68 309,-68 303,-68 297,-62 297,-56 297,-56 297,-12 297,-12 297,-6 303,0 309,0 309,0 416,0 416,0 422,0 428,-6 428,-12 428,-12 428,-56 428,-56 428,-62 422,-68 416,-68\"/>\n<text text-anchor=\"middle\" x=\"362.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.0</text>\n<text text-anchor=\"middle\" x=\"362.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 5</text>\n<text text-anchor=\"middle\" x=\"362.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 0, 5, 0]</text>\n<text text-anchor=\"middle\" x=\"362.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = Sip</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M316.0549,-103.9815C321.9715,-95.0666 328.2335,-85.6313 334.1787,-76.6734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"337.1464,-78.5311 339.76,-68.2637 331.314,-74.6602 337.1464,-78.5311\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofdkJgijN2V7",
        "colab_type": "text"
      },
      "source": [
        "# Creamos un módulo que use nuestro modelo para predecir los intents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-JI2MGHS8He",
        "colab_type": "text"
      },
      "source": [
        "## Método que representa nuestro módulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lvcD5KMObEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_intent(sentence, nlp, model):\n",
        "  vector = nlp(sentence).vector\n",
        "  \n",
        "  intent = model.predict([vector])\n",
        "  return intent[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKLKpkf0PamG",
        "colab_type": "text"
      },
      "source": [
        "## Probamos nuestro modulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoOCHl7EPcps",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3819df5-c390-42d3-d30e-3332905ace26"
      },
      "source": [
        "sentence = \"hola\"\n",
        "intent = predict_intent(sentence, nlp, decision_tree_classifier)\n",
        "intent"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chau'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMQmdE3pSTQW",
        "colab_type": "text"
      },
      "source": [
        "# Probando las predicciones de nuestro bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRfhiHc_TJ1Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "75edb8cc-3bee-4610-ec0f-543d715ea34a"
      },
      "source": [
        "while True:\n",
        "  sentence = input()\n",
        "  if sentence == \"/quit\":\n",
        "    break\n",
        "  \n",
        "  intent = predict_intent(sentence, nlp, decision_tree_classifier)\n",
        "  print(\"bot predict: {}\\n\".format(intent))\n",
        "  if intent == \"Chau\":\n",
        "    break"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola\n",
            "bot predict: Sip\n",
            "\n",
            "comida\n",
            "bot predict: Sip\n",
            "\n",
            "Comida\n",
            "bot predict: Sip\n",
            "\n",
            "Chau\n",
            "bot predict: Sip\n",
            "\n",
            "Alamos\n",
            "bot predict: Chau\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8ykiua3UlvH",
        "colab_type": "text"
      },
      "source": [
        "# Creamos un pequeño dataset de utterances asociados a sentencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iMQ6jndU5Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = \"\"\"\n",
        "*Hola\n",
        "Holas\n",
        "Que hay\n",
        "Habla\n",
        "Que fue\n",
        "Dime\n",
        "\n",
        "*Comida\n",
        "Quieres ir a comer\n",
        "Vao a almorzar\n",
        "Hamma\n",
        "Richi\n",
        "\n",
        "*Sip\n",
        "ya\n",
        "See\n",
        "Claro\n",
        "Vao\n",
        "\n",
        "*Chau\n",
        "Alamos\n",
        "Nos vemos\n",
        "Bella ciao\n",
        "Bye bye\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rItMfYwZXGPq"
      },
      "source": [
        "## Métodos para crear el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BC8s_ZrIXGPt",
        "colab": {}
      },
      "source": [
        "def filter_utterances_and_their_examples(dataset, utterance_character = \"*\"):\n",
        "  filter_list = list(filter(None, dataset.split(\"\\n\")))\n",
        "\n",
        "  utterances_examples = {}\n",
        "  utterance = \"\"\n",
        "  for element in filter_list:\n",
        "    if element[0] == utterance_character:\n",
        "      utterance = element[1:]\n",
        "    else:\n",
        "      if utterance not in utterances_examples:\n",
        "        utterances_examples[utterance] = [element]\n",
        "      else:\n",
        "        utterances_examples[utterance].append(element)\n",
        "  return utterances_examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8qQAOL8JXGPx"
      },
      "source": [
        "## Creando el dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HClXUabGXGPy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4fa65582-565c-4895-eeca-6e83cab7bbe0"
      },
      "source": [
        "#Obteniendo un diccionario de utterances con sus sentencias\n",
        "utterances_examples = filter_utterances_and_their_examples(dataset)\n",
        "utterances_examples"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Chau': ['Alamos', 'Nos vemos', 'Bella ciao', 'Bye bye'],\n",
              " 'Comida': ['Quieres ir a comer', 'Vao a almorzar', 'Hamma', 'Richi'],\n",
              " 'Hola': ['Holas', 'Que hay', 'Habla', 'Que fue', 'Dime'],\n",
              " 'Sip': ['ya', 'See', 'Claro', 'Vao']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nWH66YNWgz9",
        "colab_type": "text"
      },
      "source": [
        "## Definimos las reglas intent - utterance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ6McX2KWzQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rules = {\n",
        "    \"Hola\": \"Hola\",\n",
        "    \"Comida\": \"Comida\",\n",
        "    \"Sip\": \"Sip\",\n",
        "    \"Chau\": \"Chau\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2JCbuO2GXoZK"
      },
      "source": [
        "# Creamos un módulo que genere lo que el bot va responder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_QOiu-7DXoZo"
      },
      "source": [
        "## Método que representa nuestro módulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UzI296OgXoZ0",
        "colab": {}
      },
      "source": [
        "from random import choice\n",
        "\n",
        "def generate_answer(utterance, utterances_examples):\n",
        "  answers = utterances_examples[utterance]\n",
        "  answer = choice(answers)\n",
        "  return answer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "L7pwQL1WXoZ-"
      },
      "source": [
        "## Probamos nuestro modulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mW1dGGV5XoaB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50903538-c721-4f1f-8b78-40b111b17fe2"
      },
      "source": [
        "utterance = \"Hola\"\n",
        "answer_1 = generate_answer(utterance, utterances_examples)\n",
        "answer_2 = generate_answer(utterance, utterances_examples)\n",
        "answer_1, answer_2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Que hay', 'Habla')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeMKcwE5YbLU",
        "colab_type": "text"
      },
      "source": [
        "# Creamos el módulo para conversar con el bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hi4uKPdAYlOM"
      },
      "source": [
        "## Método que representa nuestro módulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mkzNiObPYlOV",
        "colab": {}
      },
      "source": [
        "def return_answer(sentence, nlp, model, rules, utterances_examples):\n",
        "  intent = predict_intent(sentence, nlp, decision_tree_classifier)\n",
        "  \n",
        "  utterance = rules[intent]\n",
        "  \n",
        "  answer = generate_answer(utterance, utterances_examples)\n",
        "  return answer, intent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "79J4zT75YlOt"
      },
      "source": [
        "## Probamos chatear con nuestro bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t9rWd2ZLYlO2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c0059456-a676-4881-ad0b-26719170e2a6"
      },
      "source": [
        "while True:\n",
        "  sentence = input()\n",
        "  if sentence == \"/quit\":\n",
        "    break\n",
        "  \n",
        "  answer, intent = return_answer(sentence, nlp, decision_tree_classifier, rules, utterances_examples)\n",
        "  print(\"bot says: {}\\n\".format(answer))\n",
        "  if intent == \"Chau\":\n",
        "    break"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hola\n",
            "bot says: ya\n",
            "\n",
            "Holas\n",
            "bot says: Que fue\n",
            "\n",
            "Hamma\n",
            "bot says: Quieres ir a comer\n",
            "\n",
            "ya\n",
            "bot says: See\n",
            "\n",
            "alamos\n",
            "bot says: Bye bye\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}